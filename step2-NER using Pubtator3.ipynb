{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003eef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pubmed_ids.txt\", \"r\") as file:\n",
    "    pubmed_ids = file.read().splitlines()\n",
    "    print(f\"Retrieved {len(pubmed_ids)} PubMed IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def SubmitPMIDList(pmids, Format,batch_size):\n",
    "    # Ensure pmids is a list of strings\n",
    "    if not isinstance(pmids, list):\n",
    "        print(\"[Error]: 'pmids' must be a list of PubMed IDs.\")\n",
    "        return\n",
    "\n",
    "    # Prepare the JSON payload\n",
    "    json_payload = {\"pmids\": pmids}\n",
    "    # Set headers\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Make the POST request\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/research/pubtator3-api/publications/export/\" + Format\n",
    "    r = requests.post(url, json=json_payload, headers=headers)\n",
    "    # Check the response status code\n",
    "    if r.status_code != 200:\n",
    "        print(\"[Error]: HTTP code\", r.status_code)\n",
    "        print(\"Response:\", r.text)  # Print the response body for more details\n",
    "    else:\n",
    "        # Save the response to a file\n",
    "        if(batch_size==10000):\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_1.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n",
    "        elif (batch_size==20000):\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_2.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n",
    "        elif (batch_size==30000):\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_3.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n",
    "        elif (batch_size==40000):\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_4.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n",
    "        elif (batch_size==50000):\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_5.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n",
    "        else:\n",
    "            with open('.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_6.json', 'a', encoding=\"UTF-8\") as fileread:\n",
    "                fileread.write(r.text)  # No need to encode/decode, as r.text is already a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08642b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubtator(pubmed_ids, batch_size=10000):\n",
    "    import time\n",
    "    pubtator_raw=[]\n",
    "    total_ids = len(pubmed_ids)\n",
    "    # Process IDs in batches\n",
    "    for start in range(0, total_ids, batch_size):\n",
    "        end = min(start + batch_size, total_ids)\n",
    "        batch_ids = pubmed_ids[start:end]\n",
    "        print(f\"Fetching details for IDs {start + 1} to {end} of {total_ids}...\")\n",
    "        try:\n",
    "            # Fetch records in XML format\n",
    "            for i in range(start, end, 1000):\n",
    "                SubmitPMIDList(pubmed_ids[i:i+1000],'biocjson',end)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching details for batch {start + 1}-{end}: {e}\")\n",
    "        \n",
    "        # Respect NCBI's rate limit (3 requests per second)\n",
    "        time.sleep(1 / 3)  # Add a small delay between batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ee34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator(pubmed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14aa777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "\n",
    "# List of six PubTator JSON files\n",
    "file_paths = [\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_1.json',\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_2.json',\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_3.json',\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_4.json',\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_5.json',\n",
    "    '.\\data\\steps data output\\step-2\\1_pubtator_data\\pubtator_data_6.json'\n",
    "]\n",
    "\n",
    "# List to store filtered JSON objects (Homo sapiens only)\n",
    "filtered_pubtator_json = []\n",
    "\n",
    "# Process each file incrementally\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            # Use 'item' if each file is a JSON array of objects\n",
    "            parser = ijson.items(file, 'item')\n",
    "            for obj in parser:\n",
    "                passages = obj.get('passages', [])\n",
    "                \n",
    "                # Ensure there is a second passage with annotations\n",
    "                if len(passages) > 1 and passages[1].get('annotations'):\n",
    "                    for annotation in passages[1]['annotations']:\n",
    "                        infons = annotation.get('infons', {})\n",
    "                        \n",
    "                        # Filter for Homo sapiens only\n",
    "                        if infons.get('identifier') == '9606':\n",
    "                            filtered_pubtator_json.append(obj)\n",
    "                            break  # Stop after first match\n",
    "        except ijson.JSONError as e:\n",
    "            print(f\"Error in file {file_path}: {e}\")\n",
    "    print(f\"Processed {file_path}, total filtered objects so far: {len(filtered_pubtator_json)}\")\n",
    "\n",
    "print(f\"\\nFinal number of Homo sapiens entries: {len(filtered_pubtator_json)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00aea4-431a-46d8-a9b3-4d7bbeaa5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Make sure NLTK punkt tokenizer is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def process_article(article):\n",
    "    \"\"\"\n",
    "    Process a single PubTator JSON article: split abstract into sentences and get positions.\n",
    "    \"\"\"\n",
    "    info = article.get('passages')[1]  # Assuming 2nd passage has abstract\n",
    "    abstract = info.get('text')\n",
    "    sentences = sent_tokenize(abstract, language=\"english\")\n",
    "    positions = []\n",
    "    start = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Escape special regex characters\n",
    "        escaped_sentence = sentence.translate(str.maketrans({\n",
    "            \"-\": r\"\\-\",\"\\\\\": r\"\\\\\",\"^\": r\"\\^\",\"$\": r\"\\$\",\"*\": r\"\\*\",\".\": r\"\\.\",\n",
    "            \"(\": r\"\\(\",\" )\": r\"\\)\", \"+\": r\"\\+\", \"[\": r\"\\[\", \"]\": r\"\\]\", \"{\": r\"\\{\",\n",
    "            \"}\": r\"\\}\",\"|\": r\"\\|\",\"?\": r\"\\?\"\n",
    "        }))\n",
    "        match = re.search(escaped_sentence, abstract, flags=re.M | re.I)\n",
    "        if match:\n",
    "            positions.append((start + match.start(), start + match.end()))\n",
    "            abstract = abstract[match.end():]  # Update abstract to avoid overlapping matches\n",
    "            start += match.end()\n",
    "\n",
    "    return {\n",
    "        'PMID': article.get('id'),\n",
    "        'AB': info.get('text'),\n",
    "        'SENTENCE': sentences,\n",
    "        'positions': positions,\n",
    "        'annotations': info.get('annotations'),\n",
    "        'offset': info.get('offset')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae290e-771d-4c65-9451-f480712ac644",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pubtator_json_final = []\n",
    "\n",
    "for article in filtered_pubtator_json:\n",
    "    processed = process_article(article)\n",
    "    filtered_pubtator_json_final.append(processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab6005-1572-4290-a964-30c2e049df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_pubtator_json_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c625a84-8231-44cf-a73f-4e73a8f167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, file_path in enumerate(file_paths, start=1):\n",
    "    filtered_articles = []\n",
    "\n",
    "    # Load & filter Homo sapiens entries\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        parser = ijson.items(f, 'item')\n",
    "        for obj in parser:\n",
    "            passages = obj.get('passages', [])\n",
    "            if len(passages) > 1 and passages[1].get('annotations'):\n",
    "                for annotation in passages[1]['annotations']:\n",
    "                    infons = annotation.get('infons', {})\n",
    "                    if infons.get('identifier') == '9606':\n",
    "                        filtered_articles.append(obj)\n",
    "                        break\n",
    "\n",
    "    # Process sentences & positions\n",
    "    cleaned_articles = [process_article(article) for article in filtered_articles]\n",
    "\n",
    "    # Save to JSON\n",
    "    output_file = os.path.join(output_dir, f'pubtator_data_{idx}_cleaned.json')\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        json.dump(cleaned_articles, out_f, indent=4)\n",
    "\n",
    "    print(f\"Processed and saved {len(cleaned_articles)} articles to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41033f-5a2f-4853-aa9c-0dfb44f2d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270\n",
      "9789\n",
      "16277\n",
      "22872\n",
      "27932\n",
      "28686\n"
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "file_paths = ['.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_1_cleaned.json',\n",
    "              '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_2_cleaned.json',\n",
    "              '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_3_cleaned.json',\n",
    "              '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_4_cleaned.json',\n",
    "              '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_5_cleaned.json',\n",
    "              '.\\data\\steps data output\\step-2\\2_cleaned_pubtator_data\\pubtator_data_6_cleaned.json']\n",
    "# Initialize an empty list to store JSON objects\n",
    "all_articles_details = []\n",
    "# Process the file incrementally\n",
    "for i in file_paths:\n",
    "    with open(i, 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            # Use the correct prefix for your JSON structure\n",
    "            # For a JSON array, use an empty string ('') or 'item'\n",
    "            parser = ijson.items(file, 'item')  # Adjust the prefix if needed\n",
    "            for item in parser:\n",
    "                all_articles_details.append(item)  # Add each JSON object to the list\n",
    "        except ijson.JSONError as e:\n",
    "            print(item)\n",
    "            print(f\"Skipping error: {e}\")\n",
    "    print(len(all_articles_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549f0e6-ee2b-4b8c-bce8-e542a12398c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list=[]\n",
    "error=[]\n",
    "error2=[]\n",
    "for i in all_articles_details:\n",
    "    for j in i.get('annotations'):\n",
    "        for k,l in enumerate(i.get('positions')):\n",
    "            if j.get('locations')[0].get('offset')>=l[0]+i.get('offset') and j.get('locations')[0].get('offset')<l[1]+i.get('offset'):\n",
    "                articles_list.append({'id':i.get('PMID'),'AB':i.get('AB'), 'type': j.get('infons').get('type'), \\\n",
    "                                     'identifier':j.get('infons').get('identifier'),'text':j.get('text'),'sentence':i.get('SENTENCE')[k],\\\n",
    "                                     'sentenceSize':len(i.get('SENTENCE')),'sentenceIndex':k})\n",
    "                break\n",
    "        else:\n",
    "            error.append(i)\n",
    "            error2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebef88d5-2b26-482b-86e9-922011f0994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Species', 'Disease', 'Chromosome', 'Gene', 'Variant', 'Chemical', 'CellLine', 'RefSeq'}\n"
     ]
    }
   ],
   "source": [
    "distinct_types = set()\n",
    "for i in articles_list:\n",
    "    distinct_types.add(i.get('type'))\n",
    "print(distinct_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a33b253-45b6-46c6-9f31-2145cdcb2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_pubtator_addpmid={}\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='Disease':\n",
    "        if Disease_pubtator_addpmid.get(i.get('id')):\n",
    "            Disease_pubtator_addpmid[i.get('id')]=Disease_pubtator_addpmid.get(i.get('id'))+[i]\n",
    "        else:\n",
    "            Disease_pubtator_addpmid[i.get('id')]=[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a050fb38-0de9-4308-94d2-b67730523474",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_output_json=[]\n",
    "for i,j in Disease_pubtator_addpmid.items():\n",
    "    Disease_output_json+=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb982c0-387c-4996-b375-1428049d3351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Disease_output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83c4442-c365-44af-b309-470a840418a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Disease_output_json:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a72e98-8313-42bd-b92a-ea1e02280798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB': 'Anterior segment ischemia changes can occur without detachment of any muscles. The most common cause of such ischemic changes of the anterior segment is the removal of too many rectus muscles in one operation. Twenty dog eyes and eight monkey eyes were subjected to the disinsertion and detachment of various combinations of extraocular muscles. They were sacrificed at intervals from 30 to 90 days. During the observation period, they were observed for gross and slit lamp changes. The enucleated eyes were studied microscopically for signs of ischemic and necrotic changes. Two patients who were studied, observed, and treated for anterior segment ischemia following muscle surgery are described. The changes which occur after muscle surgery are extensive and include corneal edema, cataract, chemosis, corneal changes, decreases in intraocular pressure, decreases in outflow or glaucoma and frank necrosis. The variables which lead to this reaction is described in detail. Also, some unanswered queries, such as the duration of the reaction and the time interval of the reaction after multiple muscle surgeries, are discussed.',\n",
       " 'type': 'Disease',\n",
       " 'identifier': 'MESH:C537775',\n",
       " 'sentence': 'Anterior segment ischemia changes can occur without detachment of any muscles.',\n",
       " 'sentenceSize': 10,\n",
       " 'sentenceIndex': 0,\n",
       " 'PMID': '105121',\n",
       " 'word': 'Anterior segment ischemia'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Disease_output_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a051f2-759c-4c51-8fcb-21f849bc1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Disease_deduplicated=set()\n",
    "Disease_deduplicated_count=0\n",
    "disease_list_raw=[]\n",
    "for i in Disease_output_json:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='Disease'\n",
    "        if i.get('identifier') and re.match(r'MESH:',i.get('identifier')):\n",
    "            i['MESH']=i.get('identifier')[5:]\n",
    "        else:\n",
    "            i['MESH']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Disease_deduplicated:\n",
    "            Disease_deduplicated.add(tuples)\n",
    "            disease_list_raw.append(i)\n",
    "        else:\n",
    "            Disease_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd064ad-c56c-4355-83b0-24257aed45ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249837"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disease_list_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5887033-a02d-489b-a153-24e941c96af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB': 'Anterior segment ischemia changes can occur without detachment of any muscles. The most common cause of such ischemic changes of the anterior segment is the removal of too many rectus muscles in one operation. Twenty dog eyes and eight monkey eyes were subjected to the disinsertion and detachment of various combinations of extraocular muscles. They were sacrificed at intervals from 30 to 90 days. During the observation period, they were observed for gross and slit lamp changes. The enucleated eyes were studied microscopically for signs of ischemic and necrotic changes. Two patients who were studied, observed, and treated for anterior segment ischemia following muscle surgery are described. The changes which occur after muscle surgery are extensive and include corneal edema, cataract, chemosis, corneal changes, decreases in intraocular pressure, decreases in outflow or glaucoma and frank necrosis. The variables which lead to this reaction is described in detail. Also, some unanswered queries, such as the duration of the reaction and the time interval of the reaction after multiple muscle surgeries, are discussed.',\n",
       " 'type': 'Disease',\n",
       " 'identifier': 'MESH:C537775',\n",
       " 'sentence': 'Anterior segment ischemia changes can occur without detachment of any muscles.',\n",
       " 'sentenceSize': 10,\n",
       " 'sentenceIndex': 0,\n",
       " 'PMID': '105121',\n",
       " 'word': 'Anterior segment ischemia',\n",
       " 'URL': 'https://pubmed.ncbi.nlm.nih.gov/105121',\n",
       " 'target': 'Anterior segment ischemia',\n",
       " 'entity': 'Anterior segment ischemia',\n",
       " 'MESH': 'C537775'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_list_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd34b36-8627-407f-a56f-7f27df68cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\Disease_Extraction.json', 'w') as fileread:\n",
    "        json.dump(disease_list_raw, fileread, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bda816e2-21bd-4857-8cac-8cadb5f38b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151723\n"
     ]
    }
   ],
   "source": [
    "distinct_disease = set()\n",
    "for i in disease_list_raw:\n",
    "    if(i.get('sentence')):\n",
    "        distinct_disease.add(i.get('sentence'))\n",
    "print(len(distinct_disease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b0b334f-54b9-4041-9134-7892c03e04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_gene=[]\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='Gene':\n",
    "        pubtator_gene.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a0b2007-bee8-4090-a756-2124ec792221",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_gene:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "127a7e3a-a0af-4177-ae4d-5d5751ff9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Gene_deduplicated=set()\n",
    "Gene_deduplicated_count=0\n",
    "Gene_list_raw=[]\n",
    "for i in pubtator_gene:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='Gene'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Disease_deduplicated:\n",
    "            Gene_deduplicated.add(tuples)\n",
    "            Gene_list_raw.append(i)\n",
    "        else:\n",
    "            Gene_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4771776e-be7e-40a9-8138-592f346ceb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB': 'An RNA recognition motif (RRM) of approximately 80 amino acids constitutes the core of RNA-binding domains found in a large family of proteins involved in RNA processing. The U1 RNA-binding domain of the A protein component of the human U1 small nuclear ribonucleoprotein (RNP), which encompasses the RRM sequence, was analyzed by using NMR spectroscopy. The domain of the A protein is a highly stable monomer in solution consisting of four antiparallel beta-strands and two alpha-helices. The highly conserved RNP1 and RNP2 consensus sequences, containing residues previously suggested to be involved in nucleic acid binding, are juxtaposed in adjacent beta-strands. Conserved aromatic side chains that are critical for RNA binding are clustered on the surface of the molecule adjacent to a variable loop that influences recognition of specific RNA sequences. The secondary structure and topology of the RRM are similar to those of ribosomal proteins L12 and L30, suggesting a distant evolutionary relationship between these two types of RNA-associated proteins.',\n",
       " 'type': 'Gene',\n",
       " 'identifier': '55599',\n",
       " 'sentence': 'The U1 RNA-binding domain of the A protein component of the human U1 small nuclear ribonucleoprotein (RNP), which encompasses the RRM sequence, was analyzed by using NMR spectroscopy.',\n",
       " 'sentenceSize': 6,\n",
       " 'sentenceIndex': 1,\n",
       " 'PMID': '1826055',\n",
       " 'word': 'RNP',\n",
       " 'URL': 'https://pubmed.ncbi.nlm.nih.gov/1826055',\n",
       " 'target': 'RNP',\n",
       " 'entity': 'RNP'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gene_list_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d92d94-6ed4-4e45-bfc9-b86837cc1951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773\n"
     ]
    }
   ],
   "source": [
    "distinct_gene = set()\n",
    "for i in Gene_list_raw:\n",
    "    if i.get('identifier'):\n",
    "        distinct_gene.add(i.get('identifier').lower())\n",
    "print(len(distinct_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c6cca2-ded9-4e9c-83fc-6b2fed3f3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9304\n"
     ]
    }
   ],
   "source": [
    "distinct_gene = set()\n",
    "for i in Gene_list_raw:\n",
    "    if i.get('sentence'):\n",
    "        distinct_gene.add(i.get('sentence').lower())\n",
    "print(len(distinct_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bab5d4c-d1fc-4279-9431-615e8c3a0751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781\n"
     ]
    }
   ],
   "source": [
    "distinct_gene = set()\n",
    "for i in Gene_list_raw:\n",
    "    if i.get('word'):\n",
    "        distinct_gene.add(i.get('word').lower())\n",
    "print(len(distinct_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d1442-9d32-4be5-9056-fb910b3fdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\Gene_Extraction.json', 'w') as fileread:\n",
    "        json.dump(Gene_list_raw, fileread, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a89e058-a6bb-4dc3-91a5-a114d2351580",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_chromosome=[]\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='Chromosome':\n",
    "        pubtator_chromosome.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20f87337-dfdd-4c9f-bef9-dc6e29907f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_chromosome:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48386e50-547d-4c25-a17e-e22c3a79443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Chromosome_deduplicated=set()\n",
    "Chromosome_deduplicated_count=0\n",
    "Chromosome_list_raw=[]\n",
    "for i in pubtator_chromosome:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='Chromosome'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Chromosome_deduplicated:\n",
    "            Chromosome_deduplicated.add(tuples)\n",
    "            Chromosome_list_raw.append(i)\n",
    "        else:\n",
    "            Chromosome_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fed6e-f71e-4dc5-af0b-585ec8548d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\Chromosome_Extraction.json', 'w', encoding=\"UTF-8\") as fileread:\n",
    "    json.dump(Chromosome_list_raw, fileread, indent=4)  # Convert list to JSON and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374596c-c220-44a0-9f24-064cdaf6853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_cellline:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaebff-23f7-4049-a768-e7686360cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "CellLine_deduplicated=set()\n",
    "CellLine_deduplicated_count=0\n",
    "CellLine_list_raw=[]\n",
    "for i in pubtator_cellline:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='CellLine'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in CellLine_deduplicated:\n",
    "            CellLine_deduplicated.add(tuples)\n",
    "            CellLine_list_raw.append(i)\n",
    "        else:\n",
    "            CellLine_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea7193-b0cf-40e0-9fa9-c1bf0e8efcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_cellline = set()\n",
    "for i in CellLine_list_raw:\n",
    "    distinct_cellline.add(i.get('identifier'))\n",
    "print(len(distinct_cellline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a3b97-0984-491c-8f7b-60d66ca27e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\CellLine_Extraction.json', 'w', encoding=\"UTF-8\") as fileread:\n",
    "    json.dump(CellLine_list_raw, fileread, indent=4)  # Convert list to JSON and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9734c2bc-f78e-4a5e-a0d2-b3e7b92a9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_variant=[]\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='Variant':\n",
    "        pubtator_variant.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49e00d54-a91f-4022-9050-eda28093b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_variant:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ecccc54-ea47-483d-bb5c-fe0da6a5f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Variant_deduplicated=set()\n",
    "Variant_deduplicated_count=0\n",
    "Variant_list_raw=[]\n",
    "for i in pubtator_variant:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='Variant'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Variant_deduplicated:\n",
    "            Variant_deduplicated.add(tuples)\n",
    "            Variant_list_raw.append(i)\n",
    "        else:\n",
    "            Variant_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a9020-57d9-4c3f-835e-13bb1acc15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\Variant_Extraction.json', 'w', encoding=\"UTF-8\") as fileread:\n",
    "    json.dump(Variant_list_raw, fileread, indent=4)  # Convert list to JSON and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bdf0a7-03da-472a-b949-716bef4be83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_RefSeq=[]\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='RefSeq':\n",
    "        pubtator_RefSeq.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1566d1-2c1d-4ed0-8b6d-512c584db7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pubtator_RefSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb62614-28cf-4905-a9af-6684cd40accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_RefSeq:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cd2ba-a89a-4199-8193-bb065596cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "RefSeq_deduplicated=set()\n",
    "RefSeq_deduplicated_count=0\n",
    "RefSeq_list_raw=[]\n",
    "for i in pubtator_RefSeq:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='RefSeq'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Variant_deduplicated:\n",
    "            RefSeq_deduplicated.add(tuples)\n",
    "            RefSeq_list_raw.append(i)\n",
    "        else:\n",
    "            RefSeq_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ead2b7-745a-40b0-94f6-df7e0916f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_RefSeq = set()\n",
    "for i in RefSeq_list_raw:\n",
    "    distinct_RefSeq.add(i.get('identifier'))\n",
    "print(len(distinct_RefSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3bc1e-3761-4529-9aa4-303f8c0bc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\RefSeq_Extraction.json', 'w', encoding=\"UTF-8\") as fileread:\n",
    "    json.dump(RefSeq_list_raw, fileread, indent=4)  # Convert list to JSON and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6470a230-f50e-4053-96da-79770faeb1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubtator_Chemical=[]\n",
    "for i in articles_list:\n",
    "    if i.get('type')=='Chemical':\n",
    "        pubtator_Chemical.append(i)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9745a74-7bba-450f-a203-32943018fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_Chemical:\n",
    "    identifier = i.get('identifier', '')  # Get the identifier, default to empty string if missing\n",
    "    parts = identifier.split(':')  # Split by colon\n",
    "    # Check if the identifier has at least two parts\n",
    "    if len(parts) > 1:\n",
    "        chemical = parts[1]  # Get the part after the colon\n",
    "        i['type_updated'] = category_mesh(chemical)  # Update the type\n",
    "    else:\n",
    "        i['type_updated'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c902d3da-dbf7-4ad0-852c-a89c65f3ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pubtator_Chemical:\n",
    "    i['PMID']=i.get('id')\n",
    "    i['word']=i.get('text')\n",
    "    del i['id']\n",
    "    del i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0df7c6e-8c96-4f14-9d4f-e7d936638a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "Chemical_deduplicated=set()\n",
    "Chemical_deduplicated_count=0\n",
    "Chemical_list_raw=[]\n",
    "for i in pubtator_Chemical:\n",
    "    k=i.get('PMID')\n",
    "    if k:\n",
    "        i['AB']=i.get('AB')\n",
    "        i['URL']='https://pubmed.ncbi.nlm.nih.gov/'+k\n",
    "        i['target']=i.get('word')\n",
    "        i['entity']=i.get('word')\n",
    "        i['type']='Chemical'\n",
    "        if i.get('identifier'):\n",
    "            i['identifier']=i.get('identifier')\n",
    "        else:\n",
    "            i['identifier']=''\n",
    "        tuples=(i.get(\"PMID\"),i.get(\"identifier\"),i.get(\"word\"),i.get(\"sentence\"))\n",
    "        if tuples not in Chemical_deduplicated:\n",
    "            print(i)\n",
    "            Chemical_deduplicated.add(tuples)\n",
    "            Chemical_list_raw.append(i)\n",
    "        else:\n",
    "            Chemical_deduplicated_count+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf397ce-ad8c-49a7-b9ba-26a1a2cf4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('.\\data\\steps data output\\step-2\\3_biological_entities\\Chemical_Extraction.json', 'w') as fileread:\n",
    "        json.dump(pubtator_Chemical, fileread, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
