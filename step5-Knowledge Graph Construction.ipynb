{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec8294-21d0-433c-bf7b-29bbdc295918",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_disease_chromosome_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 26892345\n",
      "Disease: recessive disease\n",
      "Chromosome: 14q24\n",
      "Relation phrase: 2q24.3 microdeletion that are associated with\n",
      "Relation type: association\n",
      "Similarity score: 0.73\n",
      "Sentence excerpt: We performed exome sequencing to examine other causes for the phenotype and queried genes present in...\n",
      "\n",
      "Example 2:\n",
      "PMID: 26892345\n",
      "Disease: recessive disease\n",
      "Chromosome: 2q24.3\n",
      "Relation phrase: microdeletion that are associated with\n",
      "Relation type: association\n",
      "Similarity score: 0.74\n",
      "Sentence excerpt: We performed exome sequencing to examine other causes for the phenotype and queried genes present in...\n",
      "\n",
      "Example 3:\n",
      "PMID: 18281524\n",
      "Disease: tumors\n",
      "Chromosome: 19p\n",
      "Relation phrase: include amplifications of 6q, 7q, 12q, and\n",
      "Relation type: mutation\n",
      "Similarity score: 0.73\n",
      "Sentence excerpt: Genomic aberrations in regions associated with differential survival (P < or = 0.05) and presence in...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    \"\"\"Get contextual embeddings from BioBERT\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def extract_relation(sentence, entity1, entity2):\n",
    "    \"\"\"Extract relationship between two entities using BioBERT embeddings\"\"\"\n",
    "    # Mark entities in sentence\n",
    "    marked_sentence = sentence.replace(entity1, f\"[E1]{entity1}[/E1]\") \\\n",
    "                             .replace(entity2, f\"[E2]{entity2}[/E2]\")\n",
    "    \n",
    "    # Get embeddings for the full sentence and entities\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    e1_embedding = get_biobert_embeddings(entity1)\n",
    "    e2_embedding = get_biobert_embeddings(entity2)\n",
    "    \n",
    "    # Find context between entities\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{entity1}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{entity2}[/E2]\")\n",
    "    \n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos+len(entity1)+10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos+len(entity2)+10:e1_pos]\n",
    "    \n",
    "    # Get relation type based on similarity to known patterns\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "    \n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity(\n",
    "            [e1_embedding], \n",
    "            [e2_embedding]\n",
    "        )[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    \"\"\"Classify relationship type based on keywords and embeddings\"\"\"\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # Predefined relation patterns and their embeddings\n",
    "    relation_patterns = {\n",
    "        \"association\": [\"associated with\", \"linked to\", \"related to\"],\n",
    "        \"location\": [\"located on\", \"found on\", \"positioned at\"],\n",
    "        \"mutation\": [\"mutated in\", \"variant in\", \"alteration in\"],\n",
    "        \"deletion\": [\"deleted in\", \"loss of\", \"missing in\"],\n",
    "        \"expression\": [\"expressed in\", \"overexpressed in\", \"underexpressed in\"]\n",
    "    }\n",
    "    \n",
    "    # Check for direct keyword matches first\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "    \n",
    "    # If no direct match, use embedding similarity\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "    \n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "    \n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    \"\"\"Process JSON file and extract relations using BioBERT\"\"\"\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease = entry['target1_word']\n",
    "            chromosome = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "            \n",
    "            relation = extract_relation(sentence, disease, chromosome)\n",
    "            \n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease\": {\n",
    "                    \"name\": disease,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"chromosome\": {\n",
    "                    \"name\": chromosome,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_chromosome_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_chromosome_relations.json\"\n",
    "    \n",
    "    print(\"Starting relation extraction with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json, limit=None)  # Remove limit for full processing\n",
    "    \n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "    \n",
    "    # Print examples\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease: {rel['disease']['name']}\")\n",
    "        print(f\"Chromosome: {rel['chromosome']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "073a2a09-2e9b-41c6-ad2d-8973b18b0fba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29607930-b7b0-42e1-bda7-0af1375041fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def extract_relation(sentence, disease, gene):\n",
    "    marked_sentence = sentence.replace(disease, f\"[E1]{disease}[/E1]\") \\\n",
    "                              .replace(gene, f\"[E2]{gene}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    disease_embedding = get_biobert_embeddings(disease)\n",
    "    gene_embedding = get_biobert_embeddings(gene)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{disease}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{gene}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos+len(disease)+10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos+len(gene)+10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity(\n",
    "            [disease_embedding], \n",
    "            [gene_embedding]\n",
    "        )[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Updated relation patterns to reflect disease-gene associations\n",
    "    relation_patterns = {\n",
    "        \"association\": [\"associated with\", \"linked to\", \"related to\", \"connected to\"],\n",
    "        \"causation\": [\"caused by\", \"due to mutation in\", \"responsible for\", \"results from\"],\n",
    "        \"mutation\": [\"mutation in\", \"mutations in\", \"variant of\", \"altered in\"],\n",
    "        \"expression\": [\"expression of\", \"overexpressed\", \"underexpressed\", \"silenced\"],\n",
    "        \"susceptibility\": [\"confers susceptibility\", \"predisposes to\", \"risk gene for\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease = entry['target1_word']\n",
    "            gene = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, disease, gene)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease\": {\n",
    "                    \"name\": disease,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"gene\": {\n",
    "                    \"name\": gene,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_gene_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_gene_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between disease and gene with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json,limit=None)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease: {rel['disease']['name']}\")\n",
    "        print(f\"Gene: {rel['gene']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab364690-29df-41b8-945c-ae6843596b62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6063"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615778ad-66d8-4558-b827-97d5ccc2f179",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between disease and disease with BioBERT...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load BioBERT and move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cache to avoid re-embedding repeated text\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    # Wrap the cached function for compatibility\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, disease1, disease2):\n",
    "    marked_sentence = sentence.replace(disease1, f\"[E1]{disease1}[/E1]\") \\\n",
    "                              .replace(disease2, f\"[E2]{disease2}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    d1_embedding = get_biobert_embeddings(disease1)\n",
    "    d2_embedding = get_biobert_embeddings(disease2)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{disease1}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{disease2}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos+len(disease1)+10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos+len(disease2)+10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "    similarity = float(cosine_similarity([d1_embedding], [d2_embedding])[0][0])\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": similarity\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"comorbidity\": [\"co-occurs with\", \"comorbid with\", \"coexisting with\"],\n",
    "        \"differential\": [\"differential diagnosis\", \"distinguished from\"],\n",
    "        \"shared_risk\": [\"share risk factors\", \"similar causes\", \"common etiology\"],\n",
    "        \"progression\": [\"leads to\", \"develops into\", \"progresses to\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease1 = entry['target1_word']\n",
    "            disease2 = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, disease1, disease2)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease1\": {\n",
    "                    \"name\": disease1,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"disease2\": {\n",
    "                    \"name\": disease2,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_disease_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_disease_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between disease and disease with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease 1: {rel['disease1']['name']}\")\n",
    "        print(f\"Disease 2: {rel['disease2']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c777985-3621-44a6-abbd-8b82069f4738",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2431cab-4d93-442f-8ac8-badd88d11c8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load BioBERT with GPU support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cache embeddings to avoid redundant computation\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, disease, variant):\n",
    "    marked_sentence = sentence.replace(disease, f\"[E1]{disease}[/E1]\") \\\n",
    "                              .replace(variant, f\"[E2]{variant}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    d_embedding = get_biobert_embeddings(disease)\n",
    "    v_embedding = get_biobert_embeddings(variant)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{disease}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{variant}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos+len(disease)+10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos+len(variant)+10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([d_embedding], [v_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"causative\": [\"caused by\", \"results from\", \"due to\"],\n",
    "        \"mutation\": [\"mutation in\", \"mutated\", \"variant of\", \"carrying the variant\", \"substitution in\"],\n",
    "        \"risk\": [\"associated with\", \"linked to\", \"confers risk for\", \"increases susceptibility to\"],\n",
    "        \"protective\": [\"protective against\", \"reduces risk of\", \"negatively associated with\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease = entry['target1_word']\n",
    "            variant = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, disease, variant)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease\": {\n",
    "                    \"name\": disease,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"variant\": {\n",
    "                    \"name\": variant,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_variant_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_variant_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between disease and variant with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease: {rel['disease']['name']}\")\n",
    "        print(f\"Variant: {rel['variant']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24af3a1b-3d5c-411c-bac5-6847f03d7f19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f0910-caf1-4c3e-8e63-f145dbb15846",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between disease and chemical with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_disease_chemical_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 25588595\n",
      "Disease: systemic embolism\n",
      "Chemical: rivaroxaban\n",
      "Relation phrase: is used to prevent stroke and\n",
      "Relation type: side_effect\n",
      "Similarity score: 0.78\n",
      "Sentence excerpt: BACKGROUND: In nonvalvular atrial fibrillation (NVAF), rivaroxaban is used to prevent stroke and sys...\n",
      "\n",
      "Example 2:\n",
      "PMID: 25588595\n",
      "Disease: stroke\n",
      "Chemical: rivaroxaban\n",
      "Relation phrase: is used to prevent\n",
      "Relation type: induction\n",
      "Similarity score: 0.68\n",
      "Sentence excerpt: BACKGROUND: In nonvalvular atrial fibrillation (NVAF), rivaroxaban is used to prevent stroke and sys...\n",
      "\n",
      "Example 3:\n",
      "PMID: 25588595\n",
      "Disease: atrial fibrillation\n",
      "Chemical: rivaroxaban\n",
      "Relation phrase: (NVAF),\n",
      "Relation type: treatment\n",
      "Similarity score: 0.73\n",
      "Sentence excerpt: BACKGROUND: In nonvalvular atrial fibrillation (NVAF), rivaroxaban is used to prevent stroke and sys...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load BioBERT with GPU acceleration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Embedding cache to speed up repeated computations\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, disease, chemical):\n",
    "    marked_sentence = sentence.replace(disease, f\"[E1]{disease}[/E1]\") \\\n",
    "                              .replace(chemical, f\"[E2]{chemical}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    d_embedding = get_biobert_embeddings(disease)\n",
    "    c_embedding = get_biobert_embeddings(chemical)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{disease}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{chemical}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos + len(disease) + 10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos + len(chemical) + 10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([d_embedding], [c_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Relation types between disease and chemical\n",
    "    relation_patterns = {\n",
    "        \"treatment\": [\"treated with\", \"alleviated by\", \"managed with\", \"therapy using\"],\n",
    "        \"induction\": [\"induced by\", \"caused by\", \"triggered by\"],\n",
    "        \"inhibition\": [\"inhibited by\", \"suppressed by\"],\n",
    "        \"resistance\": [\"resistant to\", \"not affected by\", \"ineffective against\"],\n",
    "        \"side_effect\": [\"adverse effect\", \"toxicity\", \"harmful to\", \"exacerbates\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease = entry['target1_word']\n",
    "            chemical = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, disease, chemical)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease\": {\n",
    "                    \"name\": disease,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"chemical\": {\n",
    "                    \"name\": chemical,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_chemical_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_chemical_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between disease and chemical with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease: {rel['disease']['name']}\")\n",
    "        print(f\"Chemical: {rel['chemical']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb05ab47-3dd6-427f-aaf4-0caaa06f6d8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13598"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab75e3-8757-4acf-8ac8-4d236d96245c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between gene and gene with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_gene_gene_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 30173558\n",
      "Gene 1: MMP13\n",
      "Gene 2: COL2A1\n",
      "Relation phrase: and\n",
      "Relation type: pathway\n",
      "Similarity score: 0.81\n",
      "Sentence excerpt: MMP13 and COL2A1 were more highly expressed in medial versus lateral compartment....\n",
      "\n",
      "Example 2:\n",
      "PMID: 33041797\n",
      "Gene 1: MMP13\n",
      "Gene 2: NFKBIA\n",
      "Relation phrase: NLRP3, TRIM21, GBP1, ADORA2A, PTAFR, TNF, MLNR, IL1B,\n",
      "Relation type: coexpression\n",
      "Similarity score: 0.80\n",
      "Sentence excerpt: The shared genes included MMP13, NLRP3, TRIM21, GBP1, ADORA2A, PTAFR, TNF, MLNR, IL1B, NFKBIA, ADRB2...\n",
      "\n",
      "Example 3:\n",
      "PMID: 33041797\n",
      "Gene 1: MMP13\n",
      "Gene 2: IL6\n",
      "Relation phrase: NLRP3, TRIM21, GBP1, ADORA2A, PTAFR, TNF, MLNR, IL1B, NFKBIA, ADRB2, and\n",
      "Relation type: coexpression\n",
      "Similarity score: 0.85\n",
      "Sentence excerpt: The shared genes included MMP13, NLRP3, TRIM21, GBP1, ADORA2A, PTAFR, TNF, MLNR, IL1B, NFKBIA, ADRB2...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load BioBERT model with GPU support if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cache for embedding repeated terms (genes, keywords, etc.)\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, gene1, gene2):\n",
    "    marked_sentence = sentence.replace(gene1, f\"[E1]{gene1}[/E1]\") \\\n",
    "                              .replace(gene2, f\"[E2]{gene2}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    g1_embedding = get_biobert_embeddings(gene1)\n",
    "    g2_embedding = get_biobert_embeddings(gene2)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{gene1}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{gene2}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos + len(gene1) + 10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos + len(gene2) + 10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([g1_embedding], [g2_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"interaction\": [\"interacts with\", \"binds to\", \"forms complex with\"],\n",
    "        \"regulation\": [\"regulates\", \"upregulates\", \"downregulates\", \"inhibits\", \"activates\"],\n",
    "        \"coexpression\": [\"co-expressed with\", \"coexpression of\", \"correlated with\"],\n",
    "        \"pathway\": [\"in same pathway\", \"participates in\", \"part of pathway\"],\n",
    "        \"genetic_link\": [\"genetically linked\", \"functionally associated\", \"epistatic to\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            gene1 = entry['target1_word']\n",
    "            gene2 = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, gene1, gene2)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"gene1\": {\n",
    "                    \"name\": gene1,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"gene2\": {\n",
    "                    \"name\": gene2,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/gene_gene_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_gene_gene_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between gene and gene with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Gene 1: {rel['gene1']['name']}\")\n",
    "        print(f\"Gene 2: {rel['gene2']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5faf4ad-4ab0-4847-975d-024d826c2eeb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8724"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f1e05-207e-4c80-8aa1-9bbd45524164",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between gene and chemical with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_gene_chemical_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 32393603\n",
      "Gene: isocitrate dehydrogenase\n",
      "Chemical: ivosidenib\n",
      "Relation phrase: (IDH) inhibitors\n",
      "Relation type: inhibition\n",
      "Similarity score: 0.76\n",
      "Sentence excerpt: PURPOSE: Differentiation syndrome (DS) is a serious adverse reaction of isocitrate dehydrogenase (ID...\n",
      "\n",
      "Example 2:\n",
      "PMID: 32393603\n",
      "Gene: isocitrate dehydrogenase\n",
      "Chemical: enasidenib\n",
      "Relation phrase: (IDH) inhibitors ivosidenib and\n",
      "Relation type: inhibition\n",
      "Similarity score: 0.73\n",
      "Sentence excerpt: PURPOSE: Differentiation syndrome (DS) is a serious adverse reaction of isocitrate dehydrogenase (ID...\n",
      "\n",
      "Example 3:\n",
      "PMID: 32393603\n",
      "Gene: IDH2\n",
      "Chemical: ivosidenib\n",
      "Relation phrase: and enasidenib in patients with (IDH)1- and\n",
      "Relation type: regulation\n",
      "Similarity score: 0.86\n",
      "Sentence excerpt: PURPOSE: Differentiation syndrome (DS) is a serious adverse reaction of isocitrate dehydrogenase (ID...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load BioBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device).eval()\n",
    "\n",
    "# Cache frequently used embeddings to avoid redundant computation\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def extract_relation(sentence, gene, chemical):\n",
    "    marked_sentence = sentence.replace(gene, f\"[E1]{gene}[/E1]\") \\\n",
    "                              .replace(chemical, f\"[E2]{chemical}[/E2]\")\n",
    "\n",
    "    g_embedding = get_biobert_embedding_cached(gene)\n",
    "    c_embedding = get_biobert_embedding_cached(chemical)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{gene}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{chemical}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos + len(gene) + 10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos + len(chemical) + 10:e1_pos]\n",
    "\n",
    "    relation_phrase = between_text.strip()\n",
    "    relation_type = classify_relation(relation_phrase)\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": relation_phrase,\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([g_embedding], [c_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"activation\": [\"activated by\", \"induces\", \"stimulates\", \"enhances\"],\n",
    "        \"inhibition\": [\"inhibited by\", \"suppressed by\", \"downregulated by\"],\n",
    "        \"binding\": [\"binds to\", \"interacts with\", \"affinity for\"],\n",
    "        \"regulation\": [\"regulated by\", \"controlled by\", \"modulated by\"],\n",
    "        \"metabolism\": [\"metabolized by\", \"processed by\", \"biotransformed by\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embedding_cached(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0.0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for keyword in keywords:\n",
    "            pattern_embedding = get_biobert_embedding_cached(keyword)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            gene = entry['target1_word']\n",
    "            chemical = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, gene, chemical)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"gene\": {\n",
    "                    \"name\": gene,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"chemical\": {\n",
    "                    \"name\": chemical,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/gene_chemical_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_gene_chemical_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between gene and chemical with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Gene: {rel['gene']['name']}\")\n",
    "        print(f\"Chemical: {rel['chemical']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de785f04-4a11-4be2-9341-36b40de3568b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1908"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872d533-5034-4c59-b6b9-f4ce7d882500",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between gene and chromosome with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_gene_chromosome_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 31706190\n",
      "Gene: MAP2K5\n",
      "Chromosome: chromosome 2\n",
      "Relation phrase: SKOR1, TOX3, and an intergenic region on\n",
      "Relation type: duplication\n",
      "Similarity score: 0.75\n",
      "Sentence excerpt: This study investigated whether any of the six initially discovered genomic loci associating with RL...\n",
      "\n",
      "Example 2:\n",
      "PMID: 31706190\n",
      "Gene: SKOR1\n",
      "Chromosome: chromosome 2\n",
      "Relation phrase: TOX3, and an intergenic region on\n",
      "Relation type: duplication\n",
      "Similarity score: 0.77\n",
      "Sentence excerpt: This study investigated whether any of the six initially discovered genomic loci associating with RL...\n",
      "\n",
      "Example 3:\n",
      "PMID: 31706190\n",
      "Gene: TOX3\n",
      "Chromosome: chromosome 2\n",
      "Relation phrase: and an intergenic region on\n",
      "Relation type: duplication\n",
      "Similarity score: 0.77\n",
      "Sentence excerpt: This study investigated whether any of the six initially discovered genomic loci associating with RL...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cached embeddings for repeated gene/chromosome/pattern terms\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, gene, chromosome):\n",
    "    marked_sentence = sentence.replace(gene, f\"[E1]{gene}[/E1]\") \\\n",
    "                              .replace(chromosome, f\"[E2]{chromosome}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    g_embedding = get_biobert_embeddings(gene)\n",
    "    c_embedding = get_biobert_embeddings(chromosome)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{gene}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{chromosome}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos + len(gene) + 10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos + len(chromosome) + 10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([g_embedding], [c_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"location\": [\"located on\", \"mapped to\", \"found on\", \"resides in\", \"positioned at\"],\n",
    "        \"translocation\": [\"translocated to\", \"translocated from\"],\n",
    "        \"deletion\": [\"deleted from\", \"loss at\", \"missing on\"],\n",
    "        \"duplication\": [\"duplicated at\", \"gain on\", \"copy number increase at\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            gene = entry['target1_word']\n",
    "            chromosome = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, gene, chromosome)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"gene\": {\n",
    "                    \"name\": gene,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"chromosome\": {\n",
    "                    \"name\": chromosome,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/gene_chromosome_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_gene_chromosome_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between gene and chromosome with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Gene: {rel['gene']['name']}\")\n",
    "        print(f\"Chromosome: {rel['chromosome']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d23c06-736e-4c2b-bcb2-f0af5def3447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc3a4e-d88c-4f4d-baff-c49c32cb7fe9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between gene and variant with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_gene_variant_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 33764904\n",
      "Gene: PALLD\n",
      "Variant: c.G154A\n",
      "Relation phrase: gene (NM_001166108.1:\n",
      "Relation type: unknown\n",
      "Similarity score: 0.64\n",
      "Sentence excerpt: Compartment-specific gene expression data and immunohistochemistry were also queried.RESULTSThe iden...\n",
      "\n",
      "Example 2:\n",
      "PMID: 33764904\n",
      "Gene: PALLD\n",
      "Variant: p.D52N\n",
      "Relation phrase: gene (NM_001166108.1:c.G154A:\n",
      "Relation type: unknown\n",
      "Similarity score: 0.67\n",
      "Sentence excerpt: Compartment-specific gene expression data and immunohistochemistry were also queried.RESULTSThe iden...\n",
      "\n",
      "Example 3:\n",
      "PMID: 33801891\n",
      "Gene: ERCC6\n",
      "Variant: rs2228528\n",
      "Relation phrase: in\n",
      "Relation type: association\n",
      "Similarity score: 0.77\n",
      "Sentence excerpt: This study suggests that rs2228528 in ERCC6 could be a potential predictor of response to FOLFIRINOX...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cache BioBERT embeddings for repeated phrases (genes, variants, keywords)\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, gene, variant):\n",
    "    marked_sentence = sentence.replace(gene, f\"[E1]{gene}[/E1]\") \\\n",
    "                              .replace(variant, f\"[E2]{variant}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    g_embedding = get_biobert_embeddings(gene)\n",
    "    v_embedding = get_biobert_embeddings(variant)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{gene}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{variant}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos + len(gene) + 10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos + len(variant) + 10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": float(cosine_similarity([g_embedding], [v_embedding])[0][0])\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"mutation\": [\"mutation in\", \"variant of\", \"substitution in\", \"alteration of\", \"harboring\"],\n",
    "        \"association\": [\"associated with\", \"linked to\", \"involved in\", \"correlated with\"],\n",
    "        \"expression\": [\"affects expression of\", \"expressed with\", \"disrupts\"],\n",
    "        \"function\": [\"impairs function\", \"enhances activity\", \"affects function of\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            gene = entry['target1_word']\n",
    "            variant = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, gene, variant)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"gene\": {\n",
    "                    \"name\": gene,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"variant\": {\n",
    "                    \"name\": variant,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/gene_variant_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_gene_variant_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between gene and variant with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Gene: {rel['gene']['name']}\")\n",
    "        print(f\"Variant: {rel['variant']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69bc5346-916d-4dc9-b61f-af8d21edc006",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31683b79-df98-4301-bfc4-145d273af3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting relation extraction between disease and disease with BioBERT...\n",
      "\n",
      "Relation extraction complete!\n",
      "Results saved to biobert_disease_disease_relations.json\n",
      "\n",
      "Example extracted relations:\n",
      "\n",
      "Example 1:\n",
      "PMID: 17440981\n",
      "Disease 1: neurofibromatosis type I\n",
      "Disease 2: tumors\n",
      "Relation phrase: in childhood, sometimes combined with\n",
      "Relation type: shared_risk\n",
      "Similarity score: 0.59\n",
      "Sentence excerpt: Case reports have shown that homozygosity or compound heterozygosity for MMR gene mutations can caus...\n",
      "\n",
      "Example 2:\n",
      "PMID: 24903423\n",
      "Disease 1: neurofibromatosis type 1\n",
      "Disease 2: tumors\n",
      "Relation phrase: may arise sporadically or be associated to various syndromes, namely multiple endocrine neoplasia type 2,\n",
      "Relation type: shared_risk\n",
      "Similarity score: 0.57\n",
      "Sentence excerpt: These tumors may arise sporadically or be associated to various syndromes, namely multiple endocrine...\n",
      "\n",
      "Example 3:\n",
      "PMID: 24903423\n",
      "Disease 1: neurofibromatosis type 1\n",
      "Disease 2: Von Hippel-Lindau syndrome\n",
      "Relation phrase: \n",
      "Relation type: unknown\n",
      "Similarity score: 0.77\n",
      "Sentence excerpt: These tumors may arise sporadically or be associated to various syndromes, namely multiple endocrine...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load BioBERT and move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Cache to avoid re-embedding repeated text\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_biobert_embedding_cached(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "def get_biobert_embeddings(text):\n",
    "    # Wrap the cached function for compatibility\n",
    "    return get_biobert_embedding_cached(text)\n",
    "\n",
    "def extract_relation(sentence, disease1, disease2):\n",
    "    marked_sentence = sentence.replace(disease1, f\"[E1]{disease1}[/E1]\") \\\n",
    "                              .replace(disease2, f\"[E2]{disease2}[/E2]\")\n",
    "\n",
    "    sentence_embedding = get_biobert_embeddings(marked_sentence)\n",
    "    d1_embedding = get_biobert_embeddings(disease1)\n",
    "    d2_embedding = get_biobert_embeddings(disease2)\n",
    "\n",
    "    e1_pos = marked_sentence.find(f\"[E1]{disease1}[/E1]\")\n",
    "    e2_pos = marked_sentence.find(f\"[E2]{disease2}[/E2]\")\n",
    "\n",
    "    if e1_pos < e2_pos:\n",
    "        between_text = marked_sentence[e1_pos+len(disease1)+10:e2_pos]\n",
    "    else:\n",
    "        between_text = marked_sentence[e2_pos+len(disease2)+10:e1_pos]\n",
    "\n",
    "    relation_type = classify_relation(between_text.strip())\n",
    "    similarity = float(cosine_similarity([d1_embedding], [d2_embedding])[0][0])\n",
    "\n",
    "    return {\n",
    "        \"relation_phrase\": between_text.strip(),\n",
    "        \"relation_type\": relation_type,\n",
    "        \"similarity_score\": similarity\n",
    "    }\n",
    "\n",
    "def classify_relation(text):\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "\n",
    "    relation_patterns = {\n",
    "        \"comorbidity\": [\"co-occurs with\", \"comorbid with\", \"coexisting with\"],\n",
    "        \"differential\": [\"differential diagnosis\", \"distinguished from\"],\n",
    "        \"shared_risk\": [\"share risk factors\", \"similar causes\", \"common etiology\"],\n",
    "        \"progression\": [\"leads to\", \"develops into\", \"progresses to\"]\n",
    "    }\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            return rel_type\n",
    "\n",
    "    text_embedding = get_biobert_embeddings(text)\n",
    "    best_match = \"unknown\"\n",
    "    highest_sim = 0\n",
    "\n",
    "    for rel_type, keywords in relation_patterns.items():\n",
    "        for pattern in keywords:\n",
    "            pattern_embedding = get_biobert_embeddings(pattern)\n",
    "            sim = cosine_similarity([text_embedding], [pattern_embedding])[0][0]\n",
    "            if sim > highest_sim:\n",
    "                highest_sim = sim\n",
    "                best_match = rel_type\n",
    "\n",
    "    return best_match if highest_sim > 0.7 else \"unknown\"\n",
    "\n",
    "def process_relations(input_file, output_file, limit=None):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for i, entry in enumerate(data[:limit] if limit else data):\n",
    "        try:\n",
    "            disease1 = entry['target1_word']\n",
    "            disease2 = entry['target2_word']\n",
    "            sentence = entry['sentence']\n",
    "\n",
    "            relation = extract_relation(sentence, disease1, disease2)\n",
    "\n",
    "            result = {\n",
    "                \"pmid\": entry['pmid'],\n",
    "                \"disease1\": {\n",
    "                    \"name\": disease1,\n",
    "                    \"type\": entry['target1_type'],\n",
    "                    \"identifier\": entry['target1_identifier']\n",
    "                },\n",
    "                \"disease2\": {\n",
    "                    \"name\": disease2,\n",
    "                    \"type\": entry['target2_type'],\n",
    "                    \"identifier\": entry['target2_identifier']\n",
    "                },\n",
    "                \"sentence\": sentence,\n",
    "                \"relation_info\": relation\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"./data/steps data output/step-4/Relation Extraction/disease_disease_relations.json\"\n",
    "    output_json = \"./data/steps data output/step-5/biobert_disease_disease_relations.json\"\n",
    "\n",
    "    print(\"Starting relation extraction between disease and disease with BioBERT...\")\n",
    "    results = process_relations(input_json, output_json)\n",
    "\n",
    "    print(\"\\nRelation extraction complete!\")\n",
    "    print(f\"Results saved to {output_json}\")\n",
    "\n",
    "    print(\"\\nExample extracted relations:\")\n",
    "    for i, rel in enumerate(results[:3]):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"PMID: {rel['pmid']}\")\n",
    "        print(f\"Disease 1: {rel['disease1']['name']}\")\n",
    "        print(f\"Disease 2: {rel['disease2']['name']}\")\n",
    "        print(f\"Relation phrase: {rel['relation_info']['relation_phrase']}\")\n",
    "        print(f\"Relation type: {rel['relation_info']['relation_type']}\")\n",
    "        print(f\"Similarity score: {rel['relation_info']['similarity_score']:.2f}\")\n",
    "        print(f\"Sentence excerpt: {rel['sentence'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc62f7a-fa09-409b-8196-f453648a9a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72225"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b8503-8358-4552-a15b-b70c32327319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
